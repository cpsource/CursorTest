{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2f4ae2-f739-4735-926d-c87fdf784693",
   "metadata": {},
   "source": [
    "where.from : https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n",
    "\n",
    "Many examples can be found at: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1959c-2188-48dd-86d6-c65d64cdaf4d",
   "metadata": {},
   "source": [
    "To use Boto3, you must first import it and indicate which service or services you‚Äôre going to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565972f9-3870-4256-a7aa-3f0c9f717a63",
   "metadata": {},
   "source": [
    "This code uploads data to an S3 bucket using the **boto3** library (AWS SDK for Python). Let me break it down:\n",
    "\n",
    "## Breakdown:\n",
    "\n",
    "```python\n",
    "s3.Bucket(bucket).put_object(Key='test.jpg', Body=data)\n",
    "```\n",
    "\n",
    "### **`s3`**\n",
    "- A **boto3 resource object** for S3\n",
    "- Usually created like: `s3 = boto3.resource('s3')`\n",
    "\n",
    "### **`.Bucket(bucket)`**\n",
    "- Selects a specific **S3 bucket**\n",
    "- `bucket` is a variable containing the bucket name (like `'cpbucket-investigate-001'`)\n",
    "- Returns a **Bucket object**\n",
    "\n",
    "### **`.put_object(...)`**\n",
    "- **Uploads/creates** an object (file) in the bucket\n",
    "- This is the method that actually does the upload\n",
    "\n",
    "### **`Key='test.jpg'`**\n",
    "- **`Key`** = the **filename/path** in S3\n",
    "- The file will be stored as `test.jpg` in the bucket root\n",
    "- Could also be a path like `'photos/test.jpg'` or `'uploads/2025/test.jpg'`\n",
    "\n",
    "### **`Body=data`**\n",
    "- **`Body`** = the **actual file content** to upload\n",
    "- `data` could be:\n",
    "  - File bytes: `open('image.jpg', 'rb').read()`\n",
    "  - String data: `\"Hello World\"`\n",
    "  - Stream object\n",
    "  - Binary data\n",
    "\n",
    "## Complete Example:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "# Create S3 resource\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Set bucket name\n",
    "bucket = 'cpbucket-investigate-001'\n",
    "\n",
    "# Read image file\n",
    "with open('local_image.jpg', 'rb') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Upload to S3\n",
    "s3.Bucket(bucket).put_object(Key='test.jpg', Body=data)\n",
    "```\n",
    "\n",
    "## What happens:\n",
    "\n",
    "1. **Connects** to S3 using your AWS credentials\n",
    "2. **Selects** the bucket named in `bucket` variable\n",
    "3. **Creates/uploads** a file called `test.jpg`\n",
    "4. **Stores** the content from `data` as the file content\n",
    "\n",
    "## Result:\n",
    "\n",
    "After running this code, you'd see:\n",
    "```bash\n",
    "$ aws s3 ls s3://cpbucket-investigate-001/\n",
    "2025-07-03 12:00:00       5120 test.jpg\n",
    "```\n",
    "\n",
    "## Alternative syntax:\n",
    "\n",
    "```python\n",
    "# Method 1: Using Bucket object (what you showed)\n",
    "s3.Bucket(bucket).put_object(Key='test.jpg', Body=data)\n",
    "\n",
    "# Method 2: Using client\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.put_object(Bucket=bucket, Key='test.jpg', Body=data)\n",
    "\n",
    "# Method 3: Using upload_file for local files\n",
    "s3.Bucket(bucket).upload_file('local_file.jpg', 'test.jpg')\n",
    "```\n",
    "\n",
    "## Common `Body` examples:\n",
    "\n",
    "```python\n",
    "# Upload text\n",
    "s3.Bucket(bucket).put_object(Key='note.txt', Body='Hello World')\n",
    "\n",
    "# Upload JSON\n",
    "import json\n",
    "data = {'name': 'John', 'age': 30}\n",
    "s3.Bucket(bucket).put_object(Key='data.json', Body=json.dumps(data))\n",
    "\n",
    "# Upload image file\n",
    "with open('photo.jpg', 'rb') as f:\n",
    "    s3.Bucket(bucket).put_object(Key='uploads/photo.jpg', Body=f.read())\n",
    "\n",
    "# Upload from URL download\n",
    "import requests\n",
    "response = requests.get('https://example.com/image.jpg')\n",
    "s3.Bucket(bucket).put_object(Key='downloaded.jpg', Body=response.content)\n",
    "```\n",
    "\n",
    "**In essence:** This line takes some data and saves it as `test.jpg` in your S3 bucket!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182ef1b-0b03-4df0-b1d3-11680508b5b5",
   "metadata": {},
   "source": [
    "Check where jupyter is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3155502c-3fcf-4834-a981-b1982524d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /mnt/AI-Agents-in-LangGraph/jupyter\n",
      "Files in current directory: ['.ipynb_checkpoints', 'Lesson_6_Student.ipynb', 'Lesson_1_Studenta.ipynb', 'Lesson_2_Studenta.ipynb', 'Lesson_3_Student.ipynb', 'boto3-initial.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in current directory:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945540fe-8a1d-4a3c-9950-a9ec16c5b984",
   "metadata": {},
   "source": [
    "# Run this once to load the S3 module into our env\n",
    "!pip install --upgrade nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c5eefc-e8a0-40f5-91a3-a2c194310f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Let's use Amazon S3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750c523-074e-40a9-86bc-a56a2e8774d4",
   "metadata": {},
   "source": [
    "Now that you have an s3 resource, you can make send requests to the service. The following code uses the buckets collection to print out all bucket names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd24ea9-40c6-459c-a326-bba584469d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpbucket-investigate-001\n"
     ]
    }
   ],
   "source": [
    "# Print out bucket names\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3825c00-5317-4fc8-b358-9ca6f938943a",
   "metadata": {},
   "source": [
    "You can also upload and download binary data. For example, the following uploads a new file to S3, assuming that the bucket amzn-s3-demo-bucket already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b50c48b-8cd0-4c14-94d1-ceb82ed7fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload of file boto3-initial.ipynb complete to cpbucket-investigate-001\n"
     ]
    }
   ],
   "source": [
    "bucket = \"cpbucket-investigate-001\"\n",
    "filename='boto3-initial.ipynb'\n",
    "# Upload a new file\n",
    "with open(filename, 'rb') as data:\n",
    "    s3.Bucket(bucket).put_object(Key=filename, Body=data)\n",
    "print(f\"upload of file {filename} complete to {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e47f23-fb1e-4697-9190-c325d1dde71a",
   "metadata": {},
   "source": [
    "Now get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c0ae88-6029-4053-aaa5-90dbb5873d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metadata for s3://cpbucket-investigate-001/boto3-initial.ipynb ===\n",
      "üìÅ Bucket: cpbucket-investigate-001\n",
      "üîë Key: boto3-initial.ipynb\n",
      "üìÑ Content Type: binary/octet-stream\n",
      "üìè Size: 9,750 bytes\n",
      "üïí Last Modified: 2025-07-03 11:09:47+00:00\n",
      "üè∑Ô∏è  ETag: \"684a1b6f40bbac18d1d8dddb262f5d6c\"\n",
      "üíæ Storage Class: STANDARD\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "def get_s3_metadata(bucket, key):\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        response = s3_client.head_object(Bucket=bucket, Key=key)\n",
    "        \n",
    "        print(f\"=== Metadata for s3://{bucket}/{key} ===\")\n",
    "        print(f\"üìÅ Bucket: {bucket}\")\n",
    "        print(f\"üîë Key: {key}\")\n",
    "        print(f\"üìÑ Content Type: {response.get('ContentType', 'Unknown')}\")\n",
    "        print(f\"üìè Size: {response.get('ContentLength', 0):,} bytes\")\n",
    "        print(f\"üïí Last Modified: {response.get('LastModified')}\")\n",
    "        print(f\"üè∑Ô∏è  ETag: {response.get('ETag')}\")\n",
    "        print(f\"üíæ Storage Class: {response.get('StorageClass', 'STANDARD')}\")\n",
    "        \n",
    "        # Custom metadata\n",
    "        metadata = response.get('Metadata', {})\n",
    "        if metadata:\n",
    "            print(\"üè∑Ô∏è  Custom Metadata:\")\n",
    "            for k, v in metadata.items():\n",
    "                print(f\"   {k}: {v}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting metadata: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use it\n",
    "bucket = \"cpbucket-investigate-001\"\n",
    "metadata = get_s3_metadata(bucket, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b0cb6-5fdc-4928-a325-1c7fcd3dde3d",
   "metadata": {},
   "source": [
    "Delete 'filename' if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2649a6d6-e46d-4635-b1a3-b872e0c51548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting S3 file check and cleanup...\n",
      "üìÅ Bucket: cpbucket-investigate-001\n",
      "üîë Looking for key: 'filename'\n",
      "--------------------------------------------------\n",
      "‚úÖ S3 client initialized successfully\n",
      "\n",
      "üîé Step 1: Checking if 'filename' exists...\n",
      "‚ÑπÔ∏è  File 'filename' does NOT exist (404 - Not Found)\n",
      "\n",
      "‚úì No action needed - 'filename' doesn't exist\n",
      "üéâ This is actually GOOD - the incorrectly named file isn't there!\n",
      "\n",
      "üìä Final Status: SUCCESS\n",
      "\n",
      "üìã Top-level files in bucket (no directories):\n",
      "--------------------------------------------------\n",
      "üìÑ Files at root level:\n",
      "   1. 'boto3-initial.ipynb' (9,750 bytes)\n",
      "\n",
      "üìÅ Directories at root level:\n",
      "   1. Downloads/\n",
      "--------------------------------------------------\n",
      "üí° This shows only the top level - not what's inside any directories\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def check_and_delete_file():\n",
    "    \"\"\"Check if 'filename' exists in S3 bucket and delete it if found\"\"\"\n",
    "    \n",
    "    bucket = \"cpbucket-investigate-001\"\n",
    "    key_to_check = \"filename\"  # The incorrectly named file\n",
    "    \n",
    "    print(\"üîç Starting S3 file check and cleanup...\")\n",
    "    print(f\"üìÅ Bucket: {bucket}\")\n",
    "    print(f\"üîë Looking for key: '{key_to_check}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Initialize S3 client\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "        print(\"‚úÖ S3 client initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize S3 client: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 1: Check if the file exists\n",
    "    print(f\"\\nüîé Step 1: Checking if '{key_to_check}' exists...\")\n",
    "    \n",
    "    try:\n",
    "        response = s3_client.head_object(Bucket=bucket, Key=key_to_check)\n",
    "        file_size = response.get('ContentLength', 0)\n",
    "        last_modified = response.get('LastModified', 'Unknown')\n",
    "        \n",
    "        print(f\"‚úÖ File '{key_to_check}' EXISTS!\")\n",
    "        print(f\"   üìè Size: {file_size:,} bytes\")\n",
    "        print(f\"   üïí Last Modified: {last_modified}\")\n",
    "        \n",
    "        file_exists = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if \"404\" in str(e) or \"Not Found\" in str(e) or \"NoSuchKey\" in str(e):\n",
    "            print(f\"‚ÑπÔ∏è  File '{key_to_check}' does NOT exist (404 - Not Found)\")\n",
    "            file_exists = False\n",
    "        else:\n",
    "            print(f\"‚ùå Unexpected error checking file: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # Step 2: Delete if exists\n",
    "    if file_exists:\n",
    "        print(f\"\\nüóëÔ∏è  Step 2: Deleting '{key_to_check}'...\")\n",
    "        \n",
    "        try:\n",
    "            s3_client.delete_object(Bucket=bucket, Key=key_to_check)\n",
    "            print(f\"‚úÖ Successfully deleted '{key_to_check}'\")\n",
    "            \n",
    "            # Step 3: Verify deletion\n",
    "            print(f\"\\n‚úì Step 3: Verifying deletion...\")\n",
    "            try:\n",
    "                s3_client.head_object(Bucket=bucket, Key=key_to_check)\n",
    "                print(f\"‚ö†Ô∏è  WARNING: File still exists after deletion attempt!\")\n",
    "                return False\n",
    "            except:\n",
    "                print(f\"‚úÖ Confirmed: '{key_to_check}' has been deleted\")\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error deleting file: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"\\n‚úì No action needed - '{key_to_check}' doesn't exist\")\n",
    "        print(\"üéâ This is actually GOOD - the incorrectly named file isn't there!\")\n",
    "        return True\n",
    "\n",
    "# Run the function\n",
    "result = check_and_delete_file()\n",
    "\n",
    "# Final status\n",
    "print(f\"\\nüìä Final Status: {'SUCCESS' if result else 'FAILED'}\")\n",
    "\n",
    "# Show only top-level bucket contents (no directories)\n",
    "print(f\"\\nüìã Top-level files in bucket (no directories):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Use delimiter='/' to get only top-level items\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=\"cpbucket-investigate-001\",\n",
    "        Delimiter='/'  # This separates files from directories\n",
    "    )\n",
    "    \n",
    "    # Files at root level\n",
    "    files_found = False\n",
    "    if 'Contents' in response:\n",
    "        print(\"üìÑ Files at root level:\")\n",
    "        for i, obj in enumerate(response['Contents'], 1):\n",
    "            key = obj['Key']\n",
    "            size = obj['Size']\n",
    "            modified = obj['LastModified']\n",
    "            print(f\"   {i}. '{key}' ({size:,} bytes)\")\n",
    "        files_found = True\n",
    "    \n",
    "    # Directories/prefixes at root level\n",
    "    dirs_found = False\n",
    "    if 'CommonPrefixes' in response:\n",
    "        print(\"\\nüìÅ Directories at root level:\")\n",
    "        for i, prefix in enumerate(response['CommonPrefixes'], 1):\n",
    "            dir_name = prefix['Prefix'].rstrip('/')\n",
    "            print(f\"   {i}. {dir_name}/\")\n",
    "        dirs_found = True\n",
    "    \n",
    "    if not files_found and not dirs_found:\n",
    "        print(\"   üì≠ Nothing at root level (bucket appears empty)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error listing bucket contents: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"üí° This shows only the top level - not what's inside any directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707fb33-149b-462e-8156-61f73891c912",
   "metadata": {},
   "source": [
    "see if we should upload first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1decf8c-ac31-4283-8c80-f5b7ca6ca461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking if 'boto3-initial.ipynb' needs to be uploaded...\n",
      "‚úÖ File exists in S3:\n",
      "   üè∑Ô∏è  S3 ETag: abd32a23a2a3532c75bf6337986de38d\n",
      "   üìè S3 Size: 48,123 bytes\n",
      "üìÑ Local file:\n",
      "   üè∑Ô∏è  Local MD5: ed7763ca4a8ccb0293d20ac9a4fe31d5\n",
      "   üìè Local Size: 62,178 bytes\n",
      "üîÑ Files are DIFFERENT - upload needed\n",
      "   MD5 match: False\n",
      "   Size match: False\n",
      "\n",
      "üöÄ Uploading boto3-initial.ipynb...\n",
      "‚úÖ Upload complete!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import hashlib\n",
    "\n",
    "def should_upload_file(bucket, s3_key, local_file_path):\n",
    "    \"\"\"\n",
    "    Check if local file differs from S3 file using ETag comparison\n",
    "    Returns True if upload is needed, False if files are the same\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîç Checking if '{local_file_path}' needs to be uploaded...\")\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Step 1: Check if file exists in S3\n",
    "    try:\n",
    "        s3_response = s3_client.head_object(Bucket=bucket, Key=s3_key)\n",
    "        s3_etag = s3_response['ETag'].strip('\"')  # Remove quotes\n",
    "        s3_size = s3_response['ContentLength']\n",
    "        \n",
    "        print(f\"‚úÖ File exists in S3:\")\n",
    "        print(f\"   üè∑Ô∏è  S3 ETag: {s3_etag}\")\n",
    "        print(f\"   üìè S3 Size: {s3_size:,} bytes\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        if \"404\" in str(e) or \"Not Found\" in str(e):\n",
    "            print(\"üì≠ File doesn't exist in S3 - upload needed\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Error checking S3: {e}\")\n",
    "            return True  # Upload on error to be safe\n",
    "    \n",
    "    # Step 2: Calculate local file MD5\n",
    "    try:\n",
    "        with open(local_file_path, 'rb') as f:\n",
    "            file_content = f.read()\n",
    "            local_md5 = hashlib.md5(file_content).hexdigest()\n",
    "            local_size = len(file_content)\n",
    "        \n",
    "        print(f\"üìÑ Local file:\")\n",
    "        print(f\"   üè∑Ô∏è  Local MD5: {local_md5}\")\n",
    "        print(f\"   üìè Local Size: {local_size:,} bytes\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading local file: {e}\")\n",
    "        return True  # Upload on error\n",
    "    \n",
    "    # Step 3: Compare\n",
    "    if local_md5 == s3_etag and local_size == s3_size:\n",
    "        print(\"‚úÖ Files are IDENTICAL - no upload needed\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"üîÑ Files are DIFFERENT - upload needed\")\n",
    "        print(f\"   MD5 match: {local_md5 == s3_etag}\")\n",
    "        print(f\"   Size match: {local_size == s3_size}\")\n",
    "        return True\n",
    "\n",
    "# Example usage\n",
    "bucket = \"cpbucket-investigate-001\"\n",
    "local_file = \"boto3-initial.ipynb\"\n",
    "s3_key = local_file  # Use same name in S3\n",
    "\n",
    "upload_needed = should_upload_file(bucket, s3_key, local_file)\n",
    "\n",
    "if upload_needed:\n",
    "    print(f\"\\nüöÄ Uploading {local_file}...\")\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        s3.Bucket(bucket).put_object(Key=s3_key, Body=data)\n",
    "    \n",
    "    print(\"‚úÖ Upload complete!\")\n",
    "else:\n",
    "    print(f\"\\n‚è≠Ô∏è  Skipping upload - {local_file} is already up to date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc85c71d-37d4-4d71-9c3e-2537149d8fb8",
   "metadata": {},
   "source": [
    "An **ETag** (Entity Tag) is a unique identifier that S3 assigns to each object to track changes. Think of it like a \"fingerprint\" for your file.\n",
    "\n",
    "## What is an ETag?\n",
    "\n",
    "**ETag = \"Entity Tag\"** - a string that changes whenever the file content changes.\n",
    "\n",
    "## Simple Example:\n",
    "\n",
    "```python\n",
    "# When you upload a file to S3:\n",
    "s3.put_object(Bucket='mybucket', Key='photo.jpg', Body=file_data)\n",
    "\n",
    "# S3 automatically creates an ETag like:\n",
    "# ETag: \"d41d8cd98f00b204e9800998ecf8427e\"\n",
    "```\n",
    "\n",
    "## How S3 Creates ETags:\n",
    "\n",
    "### **For Small Files (single upload):**\n",
    "```\n",
    "ETag = MD5 hash of the file content\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "# Your file content\n",
    "file_content = b\"Hello World\"\n",
    "\n",
    "# S3's ETag will be:\n",
    "etag = hashlib.md5(file_content).hexdigest()\n",
    "print(etag)  # \"b10a8db164e0754105b7a99be72e3fe5\"\n",
    "\n",
    "# In S3, it appears as: \"b10a8db164e0754105b7a99be72e3fe5\"\n",
    "```\n",
    "\n",
    "### **For Large Files (multipart upload):**\n",
    "```\n",
    "ETag = Complex hash of all parts + \"-\" + number_of_parts\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "\"abc123def456-3\"  ‚Üê File uploaded in 3 parts\n",
    "```\n",
    "\n",
    "## Real S3 ETag Examples:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.head_object(Bucket='mybucket', Key='myfile.txt')\n",
    "\n",
    "print(response['ETag'])\n",
    "# Could be:\n",
    "# \"d41d8cd98f00b204e9800998ecf8427e\"        ‚Üê Single part upload\n",
    "# \"abc123def456789-5\"                        ‚Üê Multipart upload (5 parts)\n",
    "```\n",
    "\n",
    "## Why ETags are Useful:\n",
    "\n",
    "### **1. Change Detection:**\n",
    "```python\n",
    "# Upload file\n",
    "etag1 = \"abc123\"\n",
    "\n",
    "# Modify file and upload again\n",
    "etag2 = \"def456\"  # Different ETag = file changed\n",
    "\n",
    "# Same file uploaded again\n",
    "etag3 = \"abc123\"  # Same ETag = identical content\n",
    "```\n",
    "\n",
    "### **2. Avoiding Unnecessary Uploads:**\n",
    "```python\n",
    "def should_upload(local_file, s3_etag):\n",
    "    # Calculate local file's MD5\n",
    "    with open(local_file, 'rb') as f:\n",
    "        local_md5 = hashlib.md5(f.read()).hexdigest()\n",
    "    \n",
    "    # Compare with S3's ETag\n",
    "    if local_md5 == s3_etag.strip('\"'):\n",
    "        return False  # Files identical, skip upload\n",
    "    else:\n",
    "        return True   # Files different, upload needed\n",
    "```\n",
    "\n",
    "### **3. File Integrity:**\n",
    "```python\n",
    "# Verify download worked correctly\n",
    "downloaded_md5 = hashlib.md5(downloaded_content).hexdigest()\n",
    "if downloaded_md5 == s3_etag.strip('\"'):\n",
    "    print(\"‚úÖ Download successful and verified\")\n",
    "else:\n",
    "    print(\"‚ùå Download corrupted\")\n",
    "```\n",
    "\n",
    "## ETag Format Examples:\n",
    "\n",
    "```python\n",
    "# What you see in AWS Console or API responses:\n",
    "{\n",
    "    \"ETag\": '\"d41d8cd98f00b204e9800998ecf8427e\"',    # Note the quotes!\n",
    "    \"LastModified\": \"2025-07-03T12:00:00Z\",\n",
    "    \"ContentLength\": 12345\n",
    "}\n",
    "\n",
    "# In your code, always strip the quotes:\n",
    "clean_etag = response['ETag'].strip('\"')\n",
    "# clean_etag = \"d41d8cd98f00b204e9800998ecf8427e\"\n",
    "```\n",
    "\n",
    "## Visual Example:\n",
    "\n",
    "```\n",
    "Original File:  \"Hello World\"\n",
    "     ‚Üì\n",
    "   MD5 Hash:    b10a8db164e0754105b7a99be72e3fe5\n",
    "     ‚Üì\n",
    "   S3 ETag:     \"b10a8db164e0754105b7a99be72e3fe5\"\n",
    "     ‚Üì\n",
    "Modified File:  \"Hello World!\"  (added exclamation)\n",
    "     ‚Üì\n",
    "   New MD5:     ed076287532e86365e841e92bfc50d8c\n",
    "     ‚Üì\n",
    "   New ETag:    \"ed076287532e86365e841e92bfc50d8c\"\n",
    "```\n",
    "\n",
    "## Limitations:\n",
    "\n",
    "1. **Multipart uploads** have complex ETags (not simple MD5)\n",
    "2. **Server-side encryption** can affect ETag calculation\n",
    "3. **Quotes** - always strip them: `etag.strip('\"')`\n",
    "\n",
    "## Think of ETag like:\n",
    "\n",
    "- **Git commit hash** - unique ID for each version\n",
    "- **File checksum** - detects any content changes\n",
    "- **Version number** - but more precise than timestamps\n",
    "\n",
    "**In essence:** ETag is S3's way of saying *\"This exact content has this exact fingerprint\"* - if the content changes even by one byte, the ETag changes completely!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078645af-148d-4ce9-aaf6-0cd969f8315a",
   "metadata": {},
   "source": [
    "Get bucket policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5668ebf5-c57f-49a5-85ce-27de6ff43dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking bucket policy for: cpbucket-investigate-001\n",
      "--------------------------------------------------\n",
      "‚ÑπÔ∏è  No bucket policy exists\n",
      "   This is normal - many buckets don't have policies\n",
      "   Access is controlled by IAM permissions instead\n",
      "\n",
      "==================================================\n",
      "üí° Understanding Bucket Policies:\n",
      "   ‚Ä¢ Bucket policies are OPTIONAL\n",
      "   ‚Ä¢ Most buckets rely on IAM user/role permissions\n",
      "   ‚Ä¢ Bucket policies are used for:\n",
      "     - Cross-account access\n",
      "     - Public read access\n",
      "     - IP address restrictions\n",
      "     - Advanced access controls\n",
      "\n",
      "üéØ Your bucket uses IAM permissions (which is common)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_bucket_policy_safely(bucket_name):\n",
    "    \"\"\"\n",
    "    Safely retrieve and display bucket policy, handling cases where no policy exists\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîç Checking bucket policy for: {bucket_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # Try to get the bucket policy\n",
    "        result = s3_client.get_bucket_policy(Bucket=bucket_name)\n",
    "        \n",
    "        print(\"‚úÖ Bucket policy EXISTS\")\n",
    "        print(\"\\nüìã Policy content:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Parse and pretty-print the JSON policy\n",
    "        policy_dict = json.loads(result['Policy'])\n",
    "        formatted_policy = json.dumps(policy_dict, indent=2)\n",
    "        print(formatted_policy)\n",
    "        \n",
    "        return policy_dict\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        \n",
    "        if error_code == 'NoSuchBucketPolicy':\n",
    "            print(\"‚ÑπÔ∏è  No bucket policy exists\")\n",
    "            print(\"   This is normal - many buckets don't have policies\")\n",
    "            print(\"   Access is controlled by IAM permissions instead\")\n",
    "            return None\n",
    "            \n",
    "        elif error_code == 'NoSuchBucket':\n",
    "            print(f\"‚ùå Bucket '{bucket_name}' does not exist\")\n",
    "            return None\n",
    "            \n",
    "        elif error_code == 'AccessDenied':\n",
    "            print(\"‚ùå Access denied - you don't have permission to read bucket policies\")\n",
    "            print(\"   Need s3:GetBucketPolicy permission\")\n",
    "            return None\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Error retrieving bucket policy: {error_code}\")\n",
    "            print(f\"   Full error: {e}\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "bucket = \"cpbucket-investigate-001\"\n",
    "policy = get_bucket_policy_safely(bucket)\n",
    "\n",
    "# Additional info about what this means\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üí° Understanding Bucket Policies:\")\n",
    "print(\"   ‚Ä¢ Bucket policies are OPTIONAL\")\n",
    "print(\"   ‚Ä¢ Most buckets rely on IAM user/role permissions\")\n",
    "print(\"   ‚Ä¢ Bucket policies are used for:\")\n",
    "print(\"     - Cross-account access\")\n",
    "print(\"     - Public read access\")\n",
    "print(\"     - IP address restrictions\")\n",
    "print(\"     - Advanced access controls\")\n",
    "\n",
    "if policy is None:\n",
    "    print(\"\\nüéØ Your bucket uses IAM permissions (which is common)\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Your bucket has {len(policy.get('Statement', []))} policy statement(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d37da9-7613-4762-8a54-e74a86d23982",
   "metadata": {},
   "source": [
    "Get bucket ACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b658be8-de1d-4746-9061-530c1a73cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '9XR1R9Q4ZMJRXPAR', 'HostId': '8ouReiK9mbKwpIeBoPtENn0WARlj1IeO3fFgdNdJfjaAbpNi+9SVCqRlFylx8ukIEg2ZJjxGIms=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': '8ouReiK9mbKwpIeBoPtENn0WARlj1IeO3fFgdNdJfjaAbpNi+9SVCqRlFylx8ukIEg2ZJjxGIms=', 'x-amz-request-id': '9XR1R9Q4ZMJRXPAR', 'date': 'Thu, 03 Jul 2025 11:45:09 GMT', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'Owner': {'DisplayName': 'page.cal', 'ID': '9f1bb1f3a3be62b2230294745b51f92d61c28872d8f5dc4f4f647b7785abc0f2'}, 'Grants': [{'Grantee': {'DisplayName': 'page.cal', 'ID': '9f1bb1f3a3be62b2230294745b51f92d61c28872d8f5dc4f4f647b7785abc0f2', 'Type': 'CanonicalUser'}, 'Permission': 'FULL_CONTROL'}]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Retrieve a bucket's ACL\n",
    "s3 = boto3.client('s3')\n",
    "result = s3.get_bucket_acl(Bucket=bucket)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb7838-1dc4-4c76-ace5-28536e86a0c0",
   "metadata": {},
   "source": [
    "Pretty Print ACL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c88d70fe-c2f4-4668-8761-b752f5b0197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† BUCKET OWNER:\n",
      "   Name: page.cal\n",
      "   ID: 9f1bb1f3a3be62b22302...\n",
      "\n",
      "üîê ACCESS GRANTS (1 total):\n",
      "   1. WHO: page.cal\n",
      "      TYPE: CanonicalUser\n",
      "      PERMISSION: FULL_CONTROL\n",
      "      MEANING: Can do everything (read, write, delete, manage permissions)\n",
      "\n",
      "‚úÖ SECURITY: This bucket is PRIVATE (secure)\n"
     ]
    }
   ],
   "source": [
    "def explain_acl(acl_response):\n",
    "    \"\"\"Pretty print ACL explanation\"\"\"\n",
    "    \n",
    "    print(\"üè† BUCKET OWNER:\")\n",
    "    owner = acl_response['Owner']\n",
    "    print(f\"   Name: {owner['DisplayName']}\")\n",
    "    print(f\"   ID: {owner['ID'][:20]}...\")\n",
    "    \n",
    "    print(f\"\\nüîê ACCESS GRANTS ({len(acl_response['Grants'])} total):\")\n",
    "    \n",
    "    for i, grant in enumerate(acl_response['Grants'], 1):\n",
    "        grantee = grant['Grantee']\n",
    "        permission = grant['Permission']\n",
    "        \n",
    "        print(f\"   {i}. WHO: {grantee.get('DisplayName', 'Unknown')}\")\n",
    "        print(f\"      TYPE: {grantee['Type']}\")\n",
    "        print(f\"      PERMISSION: {permission}\")\n",
    "        \n",
    "        # Explain what the permission means\n",
    "        perm_explain = {\n",
    "            'FULL_CONTROL': 'Can do everything (read, write, delete, manage permissions)',\n",
    "            'READ': 'Can list and download objects',\n",
    "            'WRITE': 'Can upload objects',\n",
    "            'READ_ACP': 'Can read permissions',\n",
    "            'WRITE_ACP': 'Can modify permissions'\n",
    "        }\n",
    "        print(f\"      MEANING: {perm_explain.get(permission, 'Unknown permission')}\")\n",
    "        print()\n",
    "    \n",
    "    # Security assessment\n",
    "    public_grants = [g for g in acl_response['Grants'] \n",
    "                    if g['Grantee'].get('URI') and 'AllUsers' in g['Grantee']['URI']]\n",
    "    \n",
    "    if public_grants:\n",
    "        print(\"‚ö†Ô∏è  SECURITY: This bucket has PUBLIC access!\")\n",
    "    else:\n",
    "        print(\"‚úÖ SECURITY: This bucket is PRIVATE (secure)\")\n",
    "\n",
    "# Use it with your ACL data\n",
    "your_acl = result\n",
    "explain_acl(your_acl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9cb94-6fe9-4487-ac8a-df06c2c42eca",
   "metadata": {},
   "source": [
    "This ACL (Access Control List) shows a **private bucket** with very basic permissions. Let me break it down:\n",
    "\n",
    "## Key Parts Explained:\n",
    "\n",
    "### **üè† Owner Information:**\n",
    "```python\n",
    "'Owner': {\n",
    "    'DisplayName': 'page.cal',                           # Your AWS account display name\n",
    "    'ID': '9f1bb1f3a3be...abc0f2'                       # Your canonical user ID (unique identifier)\n",
    "}\n",
    "```\n",
    "\n",
    "### **üîê Access Grants:**\n",
    "```python\n",
    "'Grants': [\n",
    "    {\n",
    "        'Grantee': {\n",
    "            'DisplayName': 'page.cal',                   # Same as owner\n",
    "            'ID': '9f1bb1f3a3be...abc0f2',              # Same canonical ID\n",
    "            'Type': 'CanonicalUser'                      # Type of grantee\n",
    "        },\n",
    "        'Permission': 'FULL_CONTROL'                     # What permissions they have\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "## What This Means:\n",
    "\n",
    "### **üéØ Security Level: PRIVATE**\n",
    "- **Only YOU** can access this bucket\n",
    "- **No public access** whatsoever\n",
    "- **No other AWS accounts** have access\n",
    "- **Most secure** default setting\n",
    "\n",
    "### **üîë Permission Breakdown:**\n",
    "\n",
    "| Who | Permission | What They Can Do |\n",
    "|-----|------------|------------------|\n",
    "| **page.cal (you)** | `FULL_CONTROL` | Everything - read, write, delete, manage permissions |\n",
    "| **Everyone else** | *None* | Cannot access at all |\n",
    "\n",
    "## Common ACL Patterns:\n",
    "\n",
    "### **1. Private (what you have):**\n",
    "```python\n",
    "# Only owner has access\n",
    "Grants: [\n",
    "    {'Grantee': {'ID': 'your-id'}, 'Permission': 'FULL_CONTROL'}\n",
    "]\n",
    "```\n",
    "\n",
    "### **2. Public Read:**\n",
    "```python\n",
    "# Anyone can download files\n",
    "Grants: [\n",
    "    {'Grantee': {'ID': 'your-id'}, 'Permission': 'FULL_CONTROL'},\n",
    "    {'Grantee': {'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'}, 'Permission': 'READ'}\n",
    "]\n",
    "```\n",
    "\n",
    "### **3. Shared with Another Account:**\n",
    "```python\n",
    "# You + another AWS account\n",
    "Grants: [\n",
    "    {'Grantee': {'ID': 'your-id'}, 'Permission': 'FULL_CONTROL'},\n",
    "    {'Grantee': {'ID': 'friend-id'}, 'Permission': 'READ'}\n",
    "]\n",
    "```\n",
    "\n",
    "## Your Bucket's Security Status:\n",
    "\n",
    "```\n",
    "‚úÖ SECURE - Private bucket\n",
    "   ‚îÇ\n",
    "   ‚îú‚îÄ‚îÄ üîí No public access\n",
    "   ‚îú‚îÄ‚îÄ üë§ Only you (page.cal) can access\n",
    "   ‚îú‚îÄ‚îÄ üìÇ You have full control (read/write/delete/manage)\n",
    "   ‚îî‚îÄ‚îÄ üö´ Everyone else is blocked\n",
    "```\n",
    "\n",
    "## ACL vs Bucket Policy vs IAM:\n",
    "\n",
    "| Method | Your Status | What It Controls |\n",
    "|--------|-------------|------------------|\n",
    "| **ACL** | Private (shown above) | Basic bucket-level permissions |\n",
    "| **Bucket Policy** | None (from earlier check) | Advanced JSON-based rules |\n",
    "| **IAM** | Your user permissions | What your AWS identity can do |\n",
    "\n",
    "## Pretty Print Your ACL:\n",
    "\n",
    "```python\n",
    "def explain_acl(acl_response):\n",
    "    \"\"\"Pretty print ACL explanation\"\"\"\n",
    "    \n",
    "    print(\"üè† BUCKET OWNER:\")\n",
    "    owner = acl_response['Owner']\n",
    "    print(f\"   Name: {owner['DisplayName']}\")\n",
    "    print(f\"   ID: {owner['ID'][:20]}...\")\n",
    "    \n",
    "    print(f\"\\nüîê ACCESS GRANTS ({len(acl_response['Grants'])} total):\")\n",
    "    \n",
    "    for i, grant in enumerate(acl_response['Grants'], 1):\n",
    "        grantee = grant['Grantee']\n",
    "        permission = grant['Permission']\n",
    "        \n",
    "        print(f\"   {i}. WHO: {grantee.get('DisplayName', 'Unknown')}\")\n",
    "        print(f\"      TYPE: {grantee['Type']}\")\n",
    "        print(f\"      PERMISSION: {permission}\")\n",
    "        \n",
    "        # Explain what the permission means\n",
    "        perm_explain = {\n",
    "            'FULL_CONTROL': 'Can do everything (read, write, delete, manage permissions)',\n",
    "            'READ': 'Can list and download objects',\n",
    "            'WRITE': 'Can upload objects',\n",
    "            'READ_ACP': 'Can read permissions',\n",
    "            'WRITE_ACP': 'Can modify permissions'\n",
    "        }\n",
    "        print(f\"      MEANING: {perm_explain.get(permission, 'Unknown permission')}\")\n",
    "        print()\n",
    "    \n",
    "    # Security assessment\n",
    "    public_grants = [g for g in acl_response['Grants'] \n",
    "                    if g['Grantee'].get('URI') and 'AllUsers' in g['Grantee']['URI']]\n",
    "    \n",
    "    if public_grants:\n",
    "        print(\"‚ö†Ô∏è  SECURITY: This bucket has PUBLIC access!\")\n",
    "    else:\n",
    "        print(\"‚úÖ SECURITY: This bucket is PRIVATE (secure)\")\n",
    "\n",
    "# Use it with your ACL data\n",
    "your_acl = {your_acl_response_here}\n",
    "explain_acl(your_acl)\n",
    "```\n",
    "\n",
    "## Bottom Line:\n",
    "\n",
    "**Your bucket is perfectly secure** - only you can access it, which is exactly what you want for private data. This is the **default and recommended** setting for most use cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41301d2e-f6c4-46ab-ba6a-f1ee7585fc9b",
   "metadata": {},
   "source": [
    "**\"Canonical\"** in `CanonicalUser` means **\"standard\"** or **\"official\"** - it's AWS's way of saying this is the **primary, unique identifier** for an AWS account.\n",
    "\n",
    "## What is a Canonical User?\n",
    "\n",
    "### **Canonical = Official/Standard Format**\n",
    "- **One true identifier** per AWS account\n",
    "- **Never changes** (unlike display names)\n",
    "- **Globally unique** across all AWS\n",
    "\n",
    "### **Think of it like:**\n",
    "```\n",
    "AWS Account = Person\n",
    "‚îú‚îÄ‚îÄ Display Name: \"page.cal\"           ‚Üê Can change (like a nickname)\n",
    "‚îú‚îÄ‚îÄ Email: \"page@example.com\"          ‚Üê Can change  \n",
    "‚îú‚îÄ‚îÄ Account ID: \"123456789012\"         ‚Üê Can see this sometimes\n",
    "‚îî‚îÄ‚îÄ Canonical ID: \"9f1bb1f3a3be...\"   ‚Üê NEVER changes (like a SSN)\n",
    "```\n",
    "\n",
    "## Real-World Analogy:\n",
    "\n",
    "| Real Life | AWS |\n",
    "|-----------|-----|\n",
    "| **Social Security Number** | **Canonical User ID** |\n",
    "| Your legal name | Display name (\"page.cal\") |\n",
    "| Nickname | Account alias |\n",
    "| Can change name/nickname | Can change display name |\n",
    "| SSN never changes | Canonical ID never changes |\n",
    "\n",
    "## Why AWS Uses Canonical IDs:\n",
    "\n",
    "### **1. Stability:**\n",
    "```python\n",
    "# You can change these:\n",
    "Display Name: \"page.cal\" ‚Üí \"PageCal\" ‚Üí \"Page California\"\n",
    "Email: \"old@email.com\" ‚Üí \"new@email.com\"\n",
    "\n",
    "# This NEVER changes:\n",
    "Canonical ID: \"9f1bb1f3a3be62b2230294745b51f92d61c28872d8f5dc4f4f647b7785abc0f2\"\n",
    "```\n",
    "\n",
    "### **2. Security:**\n",
    "```python\n",
    "# ACL using email (BAD - emails change):\n",
    "\"Grantee\": {\"EmailAddress\": \"friend@oldcompany.com\"}  # What if they change jobs?\n",
    "\n",
    "# ACL using Canonical ID (GOOD - never changes):\n",
    "\"Grantee\": {\"ID\": \"abc123def456...\"}  # Always points to same person\n",
    "```\n",
    "\n",
    "### **3. Global Uniqueness:**\n",
    "```python\n",
    "# Multiple people could have same display name:\n",
    "\"page.cal\" (you)\n",
    "\"page.cal\" (someone else with same name)\n",
    "\n",
    "# But Canonical IDs are guaranteed unique:\n",
    "\"9f1bb1f3a3be...\" (only you, forever)\n",
    "\"a1b2c3d4e5f6...\" (only them, forever)\n",
    "```\n",
    "\n",
    "## How to Find Your Canonical ID:\n",
    "\n",
    "### **Method 1: S3 ACL (what you did):**\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "acl = s3.get_bucket_acl(Bucket='your-bucket')\n",
    "print(\"Your Canonical ID:\", acl['Owner']['ID'])\n",
    "```\n",
    "\n",
    "### **Method 2: AWS CLI:**\n",
    "```bash\n",
    "aws s3api get-bucket-acl --bucket your-bucket --query 'Owner.ID'\n",
    "```\n",
    "\n",
    "### **Method 3: IAM (if you have permissions):**\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "user = iam.get_user()\n",
    "# Note: This gives you user ARN, not canonical ID\n",
    "```\n",
    "\n",
    "## Types of Grantees in S3:\n",
    "\n",
    "| Type | Example | Description |\n",
    "|------|---------|-------------|\n",
    "| **CanonicalUser** | `{\"ID\": \"9f1bb1f3...\"}` | AWS account (you) |\n",
    "| **AmazonCustomerByEmail** | `{\"EmailAddress\": \"user@domain.com\"}` | AWS account by email |\n",
    "| **Group** | `{\"URI\": \".../AllUsers\"}` | Predefined groups (like \"everyone\") |\n",
    "\n",
    "## Example ACL Breakdown:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'Grantee': {\n",
    "        'Type': 'CanonicalUser',                    # ‚Üê This means \"AWS account\"\n",
    "        'ID': '9f1bb1f3a3be...',                   # ‚Üê The official, permanent ID\n",
    "        'DisplayName': 'page.cal'                  # ‚Üê Human-readable name (can change)\n",
    "    },\n",
    "    'Permission': 'FULL_CONTROL'\n",
    "}\n",
    "```\n",
    "\n",
    "## Why Not Just Use Display Names?\n",
    "\n",
    "**Problem with display names:**\n",
    "```python\n",
    "# Today:\n",
    "DisplayName: \"page.cal\"\n",
    "\n",
    "# Tomorrow you change it:\n",
    "DisplayName: \"PageCaliforniaTech\"\n",
    "\n",
    "# ACLs using display names would break!\n",
    "```\n",
    "\n",
    "**Solution with Canonical IDs:**\n",
    "```python\n",
    "# Today and forever:\n",
    "CanonicalID: \"9f1bb1f3a3be62b2230294745b51f92d61c28872d8f5dc4f4f647b7785abc0f2\"\n",
    "\n",
    "# Display name can change, permissions stay intact\n",
    "```\n",
    "\n",
    "## Summary:\n",
    "\n",
    "**Canonical User** = **\"The official, permanent way to identify this AWS account\"**\n",
    "\n",
    "- **Canonical** = Official/standard format\n",
    "- **Never changes** even if you change account details\n",
    "- **Globally unique** identifier\n",
    "- **Most reliable** way for AWS to track permissions\n",
    "\n",
    "Think of it as your **AWS fingerprint** - unique to you and never changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836a514-efe5-40e7-8293-2944ca9b3c95",
   "metadata": {},
   "source": [
    "Yes! Here are several ways to create markdown cells in Jupyter:\n",
    "\n",
    "## Method 1: Keyboard Shortcuts (Fastest)\n",
    "\n",
    "### **Create new markdown cell:**\n",
    "1. **Click on any cell** to select it\n",
    "2. **Press `B`** to create a new cell below (or `A` for above)\n",
    "3. **Press `M`** to convert it to markdown\n",
    "4. **Start typing** your markdown\n",
    "\n",
    "### **Convert existing cell to markdown:**\n",
    "1. **Select the cell**\n",
    "2. **Press `M`** - instantly converts to markdown\n",
    "\n",
    "## Method 2: Dropdown Menu\n",
    "1. **Select a cell**\n",
    "2. **Click the dropdown** in toolbar (shows \"Code\" by default)\n",
    "3. **Select \"Markdown\"**\n",
    "\n",
    "## Method 3: Insert Menu\n",
    "1. **Insert** ‚Üí **Insert Cell Below** (or Above)\n",
    "2. **Change cell type** to Markdown using dropdown or `M` key\n",
    "\n",
    "## Method 4: Right-click Context Menu\n",
    "1. **Right-click on a cell**\n",
    "2. **Insert Cell Below** ‚Üí automatically creates code cell\n",
    "3. **Press `M`** to convert to markdown\n",
    "\n",
    "## Method 5: Plus Button + Convert\n",
    "1. **Click the `+` button** in toolbar (creates code cell)\n",
    "2. **Press `M`** to convert to markdown\n",
    "\n",
    "## Quick Workflow:\n",
    "```\n",
    "Click cell ‚Üí B ‚Üí M ‚Üí Type markdown ‚Üí Shift+Enter\n",
    "```\n",
    "\n",
    "**Translation:**\n",
    "- `B` = Create cell **B**elow\n",
    "- `M` = Convert to **M**arkdown  \n",
    "- `Shift+Enter` = Run/render the markdown\n",
    "\n",
    "## All Useful Shortcuts:\n",
    "\n",
    "| Shortcut | Action |\n",
    "|----------|---------|\n",
    "| **`A`** | Insert cell **A**bove |\n",
    "| **`B`** | Insert cell **B**elow |\n",
    "| **`M`** | Convert to **M**arkdown |\n",
    "| **`Y`** | Convert to Code (**Y** for \"pYthon\") |\n",
    "| **`R`** | Convert to **R**aw |\n",
    "| **`Enter`** | Edit selected cell |\n",
    "| **`Shift+Enter`** | Run cell and move to next |\n",
    "| **`Ctrl+Enter`** | Run cell and stay selected |\n",
    "\n",
    "## Visual Indicators:\n",
    "\n",
    "**Code cell:** Green border when editing, `In []:` on left\n",
    "**Markdown cell:** Blue border when editing, no `In []:` \n",
    "\n",
    "## Pro Tip:\n",
    "The **fastest way** is: `B` + `M` + start typing markdown. This becomes muscle memory quickly!\n",
    "\n",
    "**So yes, you can create markdown cells just as easily as code cells** - it's just one extra keystroke (`M`) after creating the cell!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffa8e7-c75c-4e5b-a611-ced7f91cb90a",
   "metadata": {},
   "source": [
    "# Web Site Concerns\n",
    "\n",
    "When you create an S3 static website, the URL follows a predictable pattern, but there are important security considerations.\n",
    "\n",
    "## S3 Website URL Formats:\n",
    "\n",
    "### **Standard Format:**\n",
    "```\n",
    "http://bucket-name.s3-website-region.amazonaws.com\n",
    "```\n",
    "\n",
    "### **For your bucket:**\n",
    "```\n",
    "http://cpbucket-investigate-001.s3-website-us-east-1.amazonaws.com\n",
    "```\n",
    "*(Replace `us-east-1` with your actual region)*\n",
    "\n",
    "### **Alternative Format (older):**\n",
    "```\n",
    "http://bucket-name.s3-website.region.amazonaws.com\n",
    "```\n",
    "\n",
    "## How to Enable S3 Website Hosting:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def enable_website_hosting(bucket_name, index_doc='index.html'):\n",
    "    \"\"\"Enable static website hosting on S3 bucket\"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # Configure website hosting\n",
    "        website_config = {\n",
    "            'IndexDocument': {'Suffix': index_doc},\n",
    "            'ErrorDocument': {'Key': 'error.html'}  # Optional\n",
    "        }\n",
    "        \n",
    "        s3_client.put_bucket_website(\n",
    "            Bucket=bucket_name,\n",
    "            WebsiteConfiguration=website_config\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Website hosting enabled for {bucket_name}\")\n",
    "        \n",
    "        # Get bucket region\n",
    "        response = s3_client.head_bucket(Bucket=bucket_name)\n",
    "        region = response['ResponseMetadata']['HTTPHeaders'].get('x-amz-bucket-region', 'us-east-1')\n",
    "        \n",
    "        # Construct website URL\n",
    "        website_url = f\"http://{bucket_name}.s3-website-{region}.amazonaws.com\"\n",
    "        print(f\"üåê Website URL: {website_url}\")\n",
    "        \n",
    "        return website_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error enabling website hosting: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "bucket = \"cpbucket-investigate-001\"\n",
    "url = enable_website_hosting(bucket)\n",
    "```\n",
    "\n",
    "## üö® Critical Security Concerns:\n",
    "\n",
    "### **1. PUBLIC ACCESS REQUIRED**\n",
    "```python\n",
    "# S3 websites MUST be publicly readable\n",
    "# This bucket policy is required:\n",
    "\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",           # ‚Üê EVERYONE can access\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": \"arn:aws:s3:::cpbucket-investigate-001/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **2. HTTP ONLY (No HTTPS)**\n",
    "```\n",
    "‚ùå http://bucket.s3-website-region.amazonaws.com   # No SSL\n",
    "‚úÖ https://your-domain.com                          # SSL via CloudFront\n",
    "```\n",
    "\n",
    "### **3. No Authentication**\n",
    "- **Anyone** with the URL can access files\n",
    "- **No login** or user restrictions possible\n",
    "- **All files** are publicly downloadable\n",
    "\n",
    "## Security Best Practices:\n",
    "\n",
    "### **Option 1: CloudFront + Custom Domain (Recommended)**\n",
    "```python\n",
    "# 1. Create S3 website\n",
    "# 2. Set up CloudFront distribution\n",
    "# 3. Use custom domain with SSL certificate\n",
    "# 4. Result: https://your-website.com (secure)\n",
    "```\n",
    "\n",
    "### **Option 2: Separate Bucket for Website**\n",
    "```python\n",
    "# DON'T use your main bucket for website\n",
    "# CREATE a separate public bucket:\n",
    "\n",
    "website_bucket = \"cpbucket-website-001\"  # Different from main bucket\n",
    "private_bucket = \"cpbucket-investigate-001\"  # Keep this private\n",
    "```\n",
    "\n",
    "### **Option 3: Limit Public Content**\n",
    "```python\n",
    "# Only put safe, public content in website bucket:\n",
    "# ‚úÖ index.html, styles.css, images\n",
    "# ‚ùå Private documents, code, personal data\n",
    "```\n",
    "\n",
    "## Complete Website Setup Example:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def setup_s3_website(bucket_name):\n",
    "    \"\"\"Complete S3 website setup with security considerations\"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    print(f\"üöÄ Setting up website for: {bucket_name}\")\n",
    "    print(\"‚ö†Ô∏è  WARNING: This will make the bucket PUBLIC!\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Enable website hosting\n",
    "        website_config = {\n",
    "            'IndexDocument': {'Suffix': 'index.html'},\n",
    "            'ErrorDocument': {'Key': 'error.html'}\n",
    "        }\n",
    "        \n",
    "        s3_client.put_bucket_website(\n",
    "            Bucket=bucket_name,\n",
    "            WebsiteConfiguration=website_config\n",
    "        )\n",
    "        print(\"‚úÖ Website hosting enabled\")\n",
    "        \n",
    "        # 2. Set public read policy\n",
    "        bucket_policy = {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Principal\": \"*\",\n",
    "                    \"Action\": \"s3:GetObject\",\n",
    "                    \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        s3_client.put_bucket_policy(\n",
    "            Bucket=bucket_name,\n",
    "            Policy=json.dumps(bucket_policy)\n",
    "        )\n",
    "        print(\"‚úÖ Public read policy applied\")\n",
    "        \n",
    "        # 3. Create simple index.html\n",
    "        index_content = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head><title>My S3 Website</title></head>\n",
    "        <body>\n",
    "            <h1>Hello from S3!</h1>\n",
    "            <p>This is a static website hosted on Amazon S3.</p>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key='index.html',\n",
    "            Body=index_content,\n",
    "            ContentType='text/html'\n",
    "        )\n",
    "        print(\"‚úÖ Created index.html\")\n",
    "        \n",
    "        # 4. Get website URL\n",
    "        region = s3_client.meta.region_name or 'us-east-1'\n",
    "        website_url = f\"http://{bucket_name}.s3-website-{region}.amazonaws.com\"\n",
    "        \n",
    "        print(f\"\\nüåê Website URL: {website_url}\")\n",
    "        print(f\"üîì Security Status: PUBLIC (anyone can access)\")\n",
    "        \n",
    "        return website_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage (BE CAREFUL - makes bucket public!)\n",
    "# url = setup_s3_website(\"cpbucket-website-001\")  # Use different bucket!\n",
    "```\n",
    "\n",
    "## Security Checklist:\n",
    "\n",
    "### ‚úÖ **DO:**\n",
    "- Use separate bucket for website\n",
    "- Only upload public content\n",
    "- Consider CloudFront for HTTPS\n",
    "- Monitor access logs\n",
    "- Use custom domain\n",
    "\n",
    "### ‚ùå **DON'T:**\n",
    "- Put private data in website bucket\n",
    "- Use main storage bucket for website\n",
    "- Ignore HTTPS requirements\n",
    "- Upload sensitive files\n",
    "\n",
    "## Alternative: Private Website Options\n",
    "\n",
    "If you need authentication:\n",
    "- **AWS Amplify** (with authentication)\n",
    "- **EC2 with web server** (full control)\n",
    "- **Lambda + API Gateway** (serverless)\n",
    "- **CloudFront with Lambda@Edge** (advanced)\n",
    "\n",
    "**Bottom line:** S3 websites are great for public static content, but require careful security planning since everything becomes publicly accessible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afe253-c8eb-4b42-bb11-3646ac2ef4ef",
   "metadata": {},
   "source": [
    "# How to set a bucket public\n",
    "\n",
    "Unfortunately, **no** - there's no local JSON file you can edit. AWS bucket policies must be applied through AWS APIs. But I can make it **much simpler** than navigating the AWS console!\n",
    "\n",
    "## Easy Python Way (Much Cleaner):\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def apply_bucket_policy_simple(bucket_name):\n",
    "    \"\"\"Apply public read policy to bucket - one simple function\"\"\"\n",
    "    \n",
    "    # The policy JSON\n",
    "    policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": \"*\",\n",
    "                \"Action\": \"s3:GetObject\",\n",
    "                \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Apply it\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3_client.put_bucket_policy(\n",
    "            Bucket=bucket_name,\n",
    "            Policy=json.dumps(policy)\n",
    "        )\n",
    "        print(f\"‚úÖ Public read policy applied to {bucket_name}\")\n",
    "        print(\"üåê Bucket is now publicly readable\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error applying policy: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage - just one line!\n",
    "apply_bucket_policy_simple(\"cpbucket-investigate-001\")\n",
    "```\n",
    "\n",
    "## Even Simpler - AWS CLI One-Liner:\n",
    "\n",
    "```bash\n",
    "# Create policy file\n",
    "cat > bucket-policy.json << 'EOF'\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": \"arn:aws:s3:::cpbucket-investigate-001/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Apply it\n",
    "aws s3api put-bucket-policy --bucket cpbucket-investigate-001 --policy file://bucket-policy.json\n",
    "```\n",
    "\n",
    "## Super Simple JSON Template:\n",
    "\n",
    "```python\n",
    "# Save this as a reusable function\n",
    "def make_bucket_public(bucket_name):\n",
    "    \"\"\"One-function solution to make bucket public\"\"\"\n",
    "    \n",
    "    import boto3\n",
    "    import json\n",
    "    \n",
    "    policy_json = f'''{{\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": \"arn:aws:s3:::{bucket_name}/*\"\n",
    "        }}]\n",
    "    }}'''\n",
    "    \n",
    "    boto3.client('s3').put_bucket_policy(\n",
    "        Bucket=bucket_name,\n",
    "        Policy=policy_json\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ {bucket_name} is now public\")\n",
    "\n",
    "# Usage\n",
    "make_bucket_public(\"cpbucket-investigate-001\")\n",
    "```\n",
    "\n",
    "## Alternative: Terraform (Infrastructure as Code):\n",
    "\n",
    "If you want file-based management:\n",
    "\n",
    "```hcl\n",
    "# bucket-policy.tf\n",
    "resource \"aws_s3_bucket_policy\" \"public_read\" {\n",
    "  bucket = \"cpbucket-investigate-001\"\n",
    "\n",
    "  policy = jsonencode({\n",
    "    Version = \"2012-10-17\"\n",
    "    Statement = [\n",
    "      {\n",
    "        Effect = \"Allow\"\n",
    "        Principal = \"*\"\n",
    "        Action = \"s3:GetObject\"\n",
    "        Resource = \"arn:aws:s3:::cpbucket-investigate-001/*\"\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "}\n",
    "```\n",
    "\n",
    "## Why No Local JSON File:\n",
    "\n",
    "AWS bucket policies are **server-side configurations** that must be:\n",
    "1. **Authenticated** with your AWS credentials\n",
    "2. **Validated** by AWS servers\n",
    "3. **Applied** to the actual S3 service\n",
    "\n",
    "It's like trying to edit a website by changing a local file - the changes have to be uploaded to the server.\n",
    "\n",
    "## Simplest Approach:\n",
    "\n",
    "**Just run this in Jupyter:**\n",
    "\n",
    "```python\n",
    "import boto3, json\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_bucket_policy(\n",
    "    Bucket=\"cpbucket-investigate-001\",\n",
    "    Policy=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": \"arn:aws:s3:::cpbucket-investigate-001/*\"\n",
    "        }]\n",
    "    })\n",
    ")\n",
    "print(\"‚úÖ Bucket is now public\")\n",
    "```\n",
    "\n",
    "**That's it!** Much simpler than clicking through AWS console menus, and you can save it as a reusable script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f85780-6e22-4351-addf-2d2d95e4332c",
   "metadata": {},
   "source": [
    "# Infrastructure as Code\n",
    "\n",
    "**Infrastructure as Code (IaC)** means managing your cloud resources (servers, databases, networks, etc.) using **code files** instead of clicking through web consoles.\n",
    "\n",
    "## Traditional Way vs Infrastructure as Code:\n",
    "\n",
    "### **‚ùå Traditional Way (Manual):**\n",
    "```\n",
    "1. Log into AWS Console\n",
    "2. Click \"Create S3 Bucket\"\n",
    "3. Fill out forms\n",
    "4. Click \"Create\"\n",
    "5. Navigate to IAM\n",
    "6. Click \"Create User\"\n",
    "7. Fill out more forms...\n",
    "```\n",
    "\n",
    "### **‚úÖ Infrastructure as Code:**\n",
    "```python\n",
    "# infrastructure.py\n",
    "create_s3_bucket(\"my-app-bucket\")\n",
    "create_iam_user(\"my-app-user\")\n",
    "attach_policy(user=\"my-app-user\", policy=\"S3ReadWrite\")\n",
    "```\n",
    "\n",
    "## Real Example - Your S3 Bucket:\n",
    "\n",
    "### **Manual Way:**\n",
    "1. AWS Console ‚Üí S3 ‚Üí Create Bucket\n",
    "2. Type \"cpbucket-investigate-001\"\n",
    "3. Choose region\n",
    "4. Configure settings\n",
    "5. Click through 4 screens\n",
    "6. Navigate to bucket policy\n",
    "7. Paste JSON policy\n",
    "8. Save\n",
    "\n",
    "### **Infrastructure as Code Way:**\n",
    "```hcl\n",
    "# infrastructure.tf (Terraform)\n",
    "resource \"aws_s3_bucket\" \"investigate\" {\n",
    "  bucket = \"cpbucket-investigate-001\"\n",
    "}\n",
    "\n",
    "resource \"aws_s3_bucket_policy\" \"public_read\" {\n",
    "  bucket = aws_s3_bucket.investigate.id\n",
    "  \n",
    "  policy = jsonencode({\n",
    "    Version = \"2012-10-17\"\n",
    "    Statement = [{\n",
    "      Effect = \"Allow\"\n",
    "      Principal = \"*\"\n",
    "      Action = \"s3:GetObject\"\n",
    "      Resource = \"${aws_s3_bucket.investigate.arn}/*\"\n",
    "    }]\n",
    "  })\n",
    "}\n",
    "```\n",
    "\n",
    "Then run: `terraform apply` and everything gets created!\n",
    "\n",
    "## Why Infrastructure as Code?\n",
    "\n",
    "### **üîÑ Reproducible:**\n",
    "```bash\n",
    "# Create identical infrastructure anywhere\n",
    "terraform apply  # Creates everything exactly the same\n",
    "```\n",
    "\n",
    "### **üìö Version Control:**\n",
    "```bash\n",
    "git add infrastructure.tf\n",
    "git commit -m \"Added S3 bucket for website\"\n",
    "git push  # Infrastructure changes are tracked like code\n",
    "```\n",
    "\n",
    "### **üîß Easy Changes:**\n",
    "```hcl\n",
    "# Change bucket name in file\n",
    "bucket = \"cpbucket-investigate-002\"\n",
    "\n",
    "# Apply change\n",
    "terraform apply  # Updates infrastructure automatically\n",
    "```\n",
    "\n",
    "### **üí• Easy Cleanup:**\n",
    "```bash\n",
    "terraform destroy  # Deletes everything defined in code\n",
    "```\n",
    "\n",
    "## Popular IaC Tools:\n",
    "\n",
    "### **1. Terraform (Most Popular):**\n",
    "```hcl\n",
    "resource \"aws_s3_bucket\" \"example\" {\n",
    "  bucket = \"my-bucket\"\n",
    "}\n",
    "```\n",
    "\n",
    "### **2. AWS CloudFormation:**\n",
    "```yaml\n",
    "Resources:\n",
    "  MyBucket:\n",
    "    Type: AWS::S3::Bucket\n",
    "    Properties:\n",
    "      BucketName: my-bucket\n",
    "```\n",
    "\n",
    "### **3. Pulumi (Python-based):**\n",
    "```python\n",
    "import pulumi_aws as aws\n",
    "\n",
    "bucket = aws.s3.Bucket(\"my-bucket\")\n",
    "```\n",
    "\n",
    "### **4. AWS CDK (Code):**\n",
    "```python\n",
    "from aws_cdk import aws_s3 as s3\n",
    "\n",
    "bucket = s3.Bucket(self, \"MyBucket\")\n",
    "```\n",
    "\n",
    "## Real-World Benefits:\n",
    "\n",
    "### **üè¢ For Companies:**\n",
    "```\n",
    "Traditional: \"John manually created 50 servers... John quit... nobody knows how to recreate them\"\n",
    "\n",
    "IaC: \"Here's the code file that creates everything. Anyone can run it.\"\n",
    "```\n",
    "\n",
    "### **üß™ For Testing:**\n",
    "```python\n",
    "# Create test environment\n",
    "terraform apply -var=\"env=test\"\n",
    "\n",
    "# Run tests\n",
    "run_tests()\n",
    "\n",
    "# Destroy test environment  \n",
    "terraform destroy -var=\"env=test\"\n",
    "```\n",
    "\n",
    "### **üöÄ For Scaling:**\n",
    "```hcl\n",
    "# Change one number to create 10x more servers\n",
    "count = 100  # Was 10, now 100\n",
    "```\n",
    "\n",
    "## Analogy:\n",
    "\n",
    "### **Manual Infrastructure = Building a House:**\n",
    "- Hire workers\n",
    "- Tell them what to do verbally\n",
    "- Hope they remember everything\n",
    "- Hard to build identical house later\n",
    "\n",
    "### **Infrastructure as Code = House Blueprint:**\n",
    "- Write detailed blueprint (code)\n",
    "- Give blueprint to any construction crew\n",
    "- They build identical house every time\n",
    "- Easy to modify blueprint and rebuild\n",
    "\n",
    "## Your Apartment Bot Example:\n",
    "\n",
    "Instead of manually creating:\n",
    "- S3 buckets\n",
    "- IAM users\n",
    "- Lambda functions\n",
    "- API Gateway\n",
    "\n",
    "You'd have:\n",
    "```hcl\n",
    "# apartment-bot.tf\n",
    "resource \"aws_s3_bucket\" \"data_storage\" { ... }\n",
    "resource \"aws_iam_user\" \"bot_user\" { ... }\n",
    "resource \"aws_lambda_function\" \"scraper\" { ... }\n",
    "resource \"aws_api_gateway_rest_api\" \"api\" { ... }\n",
    "```\n",
    "\n",
    "Run `terraform apply` and your entire apartment bot infrastructure gets created in minutes!\n",
    "\n",
    "## IaC vs Your Current Approach:\n",
    "\n",
    "**What you're doing now:**\n",
    "```python\n",
    "# Direct API calls (good for learning/testing)\n",
    "boto3.client('s3').create_bucket(...)\n",
    "```\n",
    "\n",
    "**Infrastructure as Code:**\n",
    "```hcl\n",
    "# Declarative files (good for production)\n",
    "resource \"aws_s3_bucket\" \"bucket\" { ... }\n",
    "```\n",
    "\n",
    "**Both are valid!** IaC becomes essential when you have complex infrastructure that needs to be reproducible, shared with teams, or managed at scale.\n",
    "\n",
    "**Think of it as:** Manual = cooking without a recipe, IaC = following a recipe that anyone can use to make the same dish perfectly every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f855a-d192-4967-b375-c4c667e8c445",
   "metadata": {},
   "source": [
    "# DNS For Web Site\n",
    "\n",
    "**Yes!** You can attach a custom domain to S3 static websites, but it requires a few steps. Here's how:\n",
    "\n",
    "## Method 1: Direct S3 Website (Simple but Limited)\n",
    "\n",
    "### **Requirements:**\n",
    "- **Domain name** (like `example.com`)\n",
    "- **DNS control** (Route 53, GoDaddy, Namecheap, etc.)\n",
    "\n",
    "### **Limitations:**\n",
    "- **HTTP only** (no SSL/HTTPS)\n",
    "- **Bucket name MUST match domain** exactly\n",
    "\n",
    "### **Example Setup:**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def setup_custom_domain_s3(domain_name):\n",
    "    \"\"\"Setup S3 website with custom domain (HTTP only)\"\"\"\n",
    "    \n",
    "    # IMPORTANT: Bucket name must match domain exactly\n",
    "    bucket_name = domain_name  # e.g., \"mysite.example.com\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # 1. Create bucket with domain name\n",
    "        s3_client.create_bucket(Bucket=bucket_name)\n",
    "        \n",
    "        # 2. Enable website hosting\n",
    "        s3_client.put_bucket_website(\n",
    "            Bucket=bucket_name,\n",
    "            WebsiteConfiguration={\n",
    "                'IndexDocument': {'Suffix': 'index.html'},\n",
    "                'ErrorDocument': {'Key': 'error.html'}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 3. Make bucket public\n",
    "        policy = {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [{\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": \"*\",\n",
    "                \"Action\": \"s3:GetObject\",\n",
    "                \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        s3_client.put_bucket_policy(\n",
    "            Bucket=bucket_name,\n",
    "            Policy=json.dumps(policy)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ S3 website setup complete for {domain_name}\")\n",
    "        print(f\"üåê S3 URL: http://{bucket_name}.s3-website-us-east-1.amazonaws.com\")\n",
    "        print(f\"üéØ Next: Create CNAME record pointing to S3 URL\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "# setup_custom_domain_s3(\"mysite.example.com\")\n",
    "```\n",
    "\n",
    "### **DNS Setup (CNAME Record):**\n",
    "```\n",
    "Type: CNAME\n",
    "Name: mysite\n",
    "Value: mysite.example.com.s3-website-us-east-1.amazonaws.com\n",
    "```\n",
    "\n",
    "**Result:** `http://mysite.example.com` ‚Üí Your S3 website\n",
    "\n",
    "## Method 2: CloudFront + Custom Domain (Recommended)\n",
    "\n",
    "### **Benefits:**\n",
    "- **HTTPS support** (SSL certificates)\n",
    "- **Better performance** (global CDN)\n",
    "- **Custom caching rules**\n",
    "- **More professional**\n",
    "\n",
    "### **Setup with CloudFront:**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def setup_cloudfront_domain(bucket_name, domain_name):\n",
    "    \"\"\"Setup S3 + CloudFront + Custom Domain with HTTPS\"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    cloudfront_client = boto3.client('cloudfront')\n",
    "    \n",
    "    try:\n",
    "        # 1. Setup S3 website (as before)\n",
    "        print(\"ü™£ Setting up S3...\")\n",
    "        # ... S3 setup code ...\n",
    "        \n",
    "        # 2. Create CloudFront distribution\n",
    "        print(\"‚òÅÔ∏è  Creating CloudFront distribution...\")\n",
    "        \n",
    "        distribution_config = {\n",
    "            'CallerReference': f'{domain_name}-{int(time.time())}',\n",
    "            'Aliases': {\n",
    "                'Quantity': 1,\n",
    "                'Items': [domain_name]\n",
    "            },\n",
    "            'Origins': {\n",
    "                'Quantity': 1,\n",
    "                'Items': [{\n",
    "                    'Id': 's3-origin',\n",
    "                    'DomainName': f'{bucket_name}.s3-website-us-east-1.amazonaws.com',\n",
    "                    'CustomOriginConfig': {\n",
    "                        'HTTPPort': 80,\n",
    "                        'HTTPSPort': 443,\n",
    "                        'OriginProtocolPolicy': 'http-only'\n",
    "                    }\n",
    "                }]\n",
    "            },\n",
    "            'DefaultCacheBehavior': {\n",
    "                'TargetOriginId': 's3-origin',\n",
    "                'ViewerProtocolPolicy': 'redirect-to-https',\n",
    "                'TrustedSigners': {\n",
    "                    'Enabled': False,\n",
    "                    'Quantity': 0\n",
    "                },\n",
    "                'ForwardedValues': {\n",
    "                    'QueryString': False,\n",
    "                    'Cookies': {'Forward': 'none'}\n",
    "                }\n",
    "            },\n",
    "            'Comment': f'CloudFront for {domain_name}',\n",
    "            'Enabled': True\n",
    "        }\n",
    "        \n",
    "        response = cloudfront_client.create_distribution(\n",
    "            DistributionConfig=distribution_config\n",
    "        )\n",
    "        \n",
    "        distribution_domain = response['Distribution']['DomainName']\n",
    "        \n",
    "        print(f\"‚úÖ CloudFront created: {distribution_domain}\")\n",
    "        print(f\"üéØ Next steps:\")\n",
    "        print(f\"   1. Get SSL certificate in AWS Certificate Manager\")\n",
    "        print(f\"   2. Create A record: {domain_name} ‚Üí {distribution_domain}\")\n",
    "        \n",
    "        return distribution_domain\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "```\n",
    "\n",
    "## Method 3: Route 53 (AWS DNS)\n",
    "\n",
    "### **If using Route 53 for DNS:**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def create_route53_record(domain_name, target):\n",
    "    \"\"\"Create Route 53 record pointing to S3 or CloudFront\"\"\"\n",
    "    \n",
    "    route53_client = boto3.client('route53')\n",
    "    \n",
    "    try:\n",
    "        # Find hosted zone\n",
    "        zones = route53_client.list_hosted_zones()\n",
    "        \n",
    "        zone_id = None\n",
    "        for zone in zones['HostedZones']:\n",
    "            if domain_name.endswith(zone['Name'].rstrip('.')):\n",
    "                zone_id = zone['Id']\n",
    "                break\n",
    "        \n",
    "        if not zone_id:\n",
    "            print(f\"‚ùå No hosted zone found for {domain_name}\")\n",
    "            return False\n",
    "        \n",
    "        # Create A record\n",
    "        route53_client.change_resource_record_sets(\n",
    "            HostedZoneId=zone_id,\n",
    "            ChangeBatch={\n",
    "                'Changes': [{\n",
    "                    'Action': 'CREATE',\n",
    "                    'ResourceRecordSet': {\n",
    "                        'Name': domain_name,\n",
    "                        'Type': 'CNAME',\n",
    "                        'TTL': 300,\n",
    "                        'ResourceRecords': [{'Value': target}]\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ DNS record created: {domain_name} ‚Üí {target}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå DNS error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "# create_route53_record(\"mysite.example.com\", \"mysite.example.com.s3-website-us-east-1.amazonaws.com\")\n",
    "```\n",
    "\n",
    "## Step-by-Step Process:\n",
    "\n",
    "### **Option A: Simple HTTP (S3 only):**\n",
    "1. **Create bucket** with exact domain name\n",
    "2. **Enable website hosting**\n",
    "3. **Make bucket public**\n",
    "4. **Create CNAME record** in your DNS\n",
    "\n",
    "### **Option B: Professional HTTPS (S3 + CloudFront):**\n",
    "1. **Create S3 website** (any bucket name)\n",
    "2. **Create CloudFront distribution**\n",
    "3. **Get SSL certificate** (AWS Certificate Manager)\n",
    "4. **Create A/ALIAS record** in DNS\n",
    "\n",
    "## DNS Record Examples:\n",
    "\n",
    "### **For S3 Direct (HTTP only):**\n",
    "```\n",
    "Type: CNAME\n",
    "Name: mysite\n",
    "Value: mysite.example.com.s3-website-us-east-1.amazonaws.com\n",
    "TTL: 300\n",
    "```\n",
    "\n",
    "### **For CloudFront (HTTPS):**\n",
    "```\n",
    "Type: A (Alias)\n",
    "Name: mysite\n",
    "Value: d1234567890.cloudfront.net\n",
    "TTL: 300\n",
    "```\n",
    "\n",
    "## Complete Example:\n",
    "\n",
    "```python\n",
    "def setup_professional_website(domain_name):\n",
    "    \"\"\"Complete setup: S3 + CloudFront + Custom Domain + HTTPS\"\"\"\n",
    "    \n",
    "    print(f\"üöÄ Setting up professional website for {domain_name}\")\n",
    "    \n",
    "    # 1. Create S3 bucket (can be any name)\n",
    "    bucket_name = f\"website-{domain_name.replace('.', '-')}\"\n",
    "    \n",
    "    # 2. Setup S3 website\n",
    "    setup_s3_website(bucket_name)\n",
    "    \n",
    "    # 3. Create CloudFront distribution\n",
    "    cloudfront_domain = setup_cloudfront_domain(bucket_name, domain_name)\n",
    "    \n",
    "    # 4. Instructions for final steps\n",
    "    print(f\"\"\"\n",
    "    ‚úÖ Technical setup complete!\n",
    "    \n",
    "    üéØ Final steps (manual):\n",
    "    1. Go to AWS Certificate Manager\n",
    "    2. Request SSL certificate for {domain_name}\n",
    "    3. Add certificate to CloudFront distribution\n",
    "    4. Create DNS record:\n",
    "       Type: A (Alias)\n",
    "       Name: {domain_name}\n",
    "       Value: {cloudfront_domain}\n",
    "    \n",
    "    üåê Result: https://{domain_name} (secure!)\n",
    "    \"\"\")\n",
    "\n",
    "# Usage\n",
    "# setup_professional_website(\"myawesome-site.com\")\n",
    "```\n",
    "\n",
    "## Summary:\n",
    "\n",
    "| Method | URL | SSL | Complexity | Cost |\n",
    "|--------|-----|-----|-----------|------|\n",
    "| **S3 Direct** | `http://domain.com` | ‚ùå No | Simple | ~$0.50/month |\n",
    "| **S3 + CloudFront** | `https://domain.com` | ‚úÖ Yes | Medium | ~$1-5/month |\n",
    "| **Route 53 + CloudFront** | `https://domain.com` | ‚úÖ Yes | Complex | ~$5-10/month |\n",
    "\n",
    "**Recommendation:** Use **S3 + CloudFront** for a professional website with HTTPS support!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd827c1e-20d0-47f6-bde6-f0ee51eb2349",
   "metadata": {},
   "source": [
    "# CloudFront\n",
    "\n",
    "**CloudFront** is Amazon's **Content Delivery Network (CDN)** - think of it as a global network of servers that cache and deliver your website content from locations close to your users.\n",
    "\n",
    "## What is CloudFront?\n",
    "\n",
    "### **Simple Analogy:**\n",
    "```\n",
    "Without CloudFront:\n",
    "User in Tokyo ‚Üí Requests your website ‚Üí Your server in Virginia ‚Üí Slow response\n",
    "\n",
    "With CloudFront:\n",
    "User in Tokyo ‚Üí Requests your website ‚Üí CloudFront server in Tokyo ‚Üí Fast response\n",
    "```\n",
    "\n",
    "## How CloudFront Works:\n",
    "\n",
    "### **The Process:**\n",
    "```\n",
    "1. User visits your website\n",
    "2. CloudFront checks: \"Do I have this content cached nearby?\"\n",
    "3. If YES: Serve from nearby edge location (fast)\n",
    "4. If NO: Get from origin (S3), cache it, then serve (first time slower, then fast)\n",
    "```\n",
    "\n",
    "### **Visual Example:**\n",
    "```\n",
    "Your S3 Bucket (Virginia)\n",
    "         ‚Üì\n",
    "    CloudFront\n",
    "    ‚Üô    ‚Üì    ‚Üò\n",
    "Tokyo  London  Sydney\n",
    "Edge   Edge    Edge\n",
    "Location Location Location\n",
    "   ‚Üì      ‚Üì       ‚Üì\n",
    "Japanese European Australian\n",
    "Users    Users    Users\n",
    "```\n",
    "\n",
    "## Real-World Example:\n",
    "\n",
    "### **Without CloudFront:**\n",
    "```python\n",
    "# User in Australia visits your S3 website\n",
    "User Request ‚Üí Virginia S3 ‚Üí 800ms response time\n",
    "```\n",
    "\n",
    "### **With CloudFront:**\n",
    "```python\n",
    "# First visit:\n",
    "User Request ‚Üí Sydney CloudFront ‚Üí Virginia S3 ‚Üí Cache in Sydney ‚Üí 800ms\n",
    "\n",
    "# Subsequent visits:\n",
    "User Request ‚Üí Sydney CloudFront ‚Üí Cached content ‚Üí 50ms response time\n",
    "```\n",
    "\n",
    "## What CloudFront Does for Your S3 Website:\n",
    "\n",
    "### **1. Speed Boost:**\n",
    "```\n",
    "Before: üêå 800ms load time (cross-continent)\n",
    "After:  ‚ö° 50ms load time (local cache)\n",
    "```\n",
    "\n",
    "### **2. HTTPS Support:**\n",
    "```\n",
    "S3 Website:     http://bucket.s3-website-region.amazonaws.com  ‚ùå No SSL\n",
    "CloudFront:     https://your-domain.com                        ‚úÖ SSL enabled\n",
    "```\n",
    "\n",
    "### **3. Custom Domains:**\n",
    "```\n",
    "S3 Website:     http://ugly-bucket-name.s3-website-us-east-1.amazonaws.com\n",
    "CloudFront:     https://myawesome-website.com\n",
    "```\n",
    "\n",
    "### **4. Global Performance:**\n",
    "```\n",
    "Edge Locations: 400+ worldwide\n",
    "Coverage: 99% of internet users within 1 hop\n",
    "Latency: <100ms for most users\n",
    "```\n",
    "\n",
    "## CloudFront Setup for Your S3 Website:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def create_cloudfront_for_s3(bucket_name, domain_name=None):\n",
    "    \"\"\"Create CloudFront distribution for S3 static website\"\"\"\n",
    "    \n",
    "    cloudfront = boto3.client('cloudfront')\n",
    "    \n",
    "    # S3 website endpoint\n",
    "    s3_website_url = f\"{bucket_name}.s3-website-us-east-1.amazonaws.com\"\n",
    "    \n",
    "    distribution_config = {\n",
    "        'CallerReference': f'{bucket_name}-{int(time.time())}',\n",
    "        'Comment': f'CloudFront for {bucket_name}',\n",
    "        'Enabled': True,\n",
    "        \n",
    "        # Where to get the content (your S3 bucket)\n",
    "        'Origins': {\n",
    "            'Quantity': 1,\n",
    "            'Items': [{\n",
    "                'Id': 's3-origin',\n",
    "                'DomainName': s3_website_url,\n",
    "                'CustomOriginConfig': {\n",
    "                    'HTTPPort': 80,\n",
    "                    'HTTPSPort': 443,\n",
    "                    'OriginProtocolPolicy': 'http-only'\n",
    "                }\n",
    "            }]\n",
    "        },\n",
    "        \n",
    "        # How to handle requests\n",
    "        'DefaultCacheBehavior': {\n",
    "            'TargetOriginId': 's3-origin',\n",
    "            'ViewerProtocolPolicy': 'redirect-to-https',  # Force HTTPS\n",
    "            'Compress': True,  # Compress files for faster delivery\n",
    "            'TrustedSigners': {'Enabled': False, 'Quantity': 0},\n",
    "            'ForwardedValues': {\n",
    "                'QueryString': False,\n",
    "                'Cookies': {'Forward': 'none'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add custom domain if provided\n",
    "    if domain_name:\n",
    "        distribution_config['Aliases'] = {\n",
    "            'Quantity': 1,\n",
    "            'Items': [domain_name]\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = cloudfront.create_distribution(DistributionConfig=distribution_config)\n",
    "        \n",
    "        distribution_id = response['Distribution']['Id']\n",
    "        cloudfront_domain = response['Distribution']['DomainName']\n",
    "        \n",
    "        print(f\"‚úÖ CloudFront distribution created!\")\n",
    "        print(f\"üìã Distribution ID: {distribution_id}\")\n",
    "        print(f\"üåê CloudFront URL: https://{cloudfront_domain}\")\n",
    "        \n",
    "        if domain_name:\n",
    "            print(f\"üéØ Custom domain: https://{domain_name} (after DNS setup)\")\n",
    "        \n",
    "        print(f\"‚è≥ Status: Deploying (takes 5-15 minutes)\")\n",
    "        \n",
    "        return {\n",
    "            'distribution_id': distribution_id,\n",
    "            'cloudfront_domain': cloudfront_domain,\n",
    "            'status': 'InProgress'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating CloudFront: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "result = create_cloudfront_for_s3(\"cpbucket-investigate-001\", \"mysite.example.com\")\n",
    "```\n",
    "\n",
    "## Benefits of CloudFront:\n",
    "\n",
    "### **üöÄ Performance:**\n",
    "- **Global caching** - content served from nearest location\n",
    "- **Compression** - files automatically compressed\n",
    "- **HTTP/2** - faster protocol support\n",
    "\n",
    "### **üîí Security:**\n",
    "- **SSL/TLS** - Free SSL certificates\n",
    "- **DDoS protection** - Built-in protection\n",
    "- **Origin hiding** - S3 bucket not directly accessible\n",
    "\n",
    "### **üí∞ Cost Optimization:**\n",
    "- **Reduced S3 costs** - Less data transfer from S3\n",
    "- **Bandwidth optimization** - Compression reduces data usage\n",
    "\n",
    "### **üåç Global Reach:**\n",
    "```\n",
    "Edge Locations:\n",
    "- North America: 100+ locations\n",
    "- Europe: 80+ locations  \n",
    "- Asia Pacific: 100+ locations\n",
    "- South America: 20+ locations\n",
    "- Africa: 10+ locations\n",
    "- Middle East: 15+ locations\n",
    "```\n",
    "\n",
    "## CloudFront vs Direct S3:\n",
    "\n",
    "| Feature | Direct S3 Website | S3 + CloudFront |\n",
    "|---------|-------------------|------------------|\n",
    "| **Speed** | Slow (single region) | Fast (global cache) |\n",
    "| **HTTPS** | ‚ùå No | ‚úÖ Yes |\n",
    "| **Custom Domain** | Limited | ‚úÖ Full support |\n",
    "| **Global Performance** | ‚ùå Poor | ‚úÖ Excellent |\n",
    "| **Cost** | Lower | Slightly higher |\n",
    "| **Setup Complexity** | Simple | Medium |\n",
    "\n",
    "## Real Performance Example:\n",
    "\n",
    "### **Your S3 bucket in Virginia, users worldwide:**\n",
    "\n",
    "```python\n",
    "# Without CloudFront:\n",
    "Tokyo user:      800ms load time\n",
    "London user:     400ms load time  \n",
    "Sydney user:     900ms load time\n",
    "New York user:   100ms load time\n",
    "\n",
    "# With CloudFront:\n",
    "Tokyo user:      80ms load time  (10x faster!)\n",
    "London user:     60ms load time  (7x faster!)\n",
    "Sydney user:     90ms load time  (10x faster!)\n",
    "New York user:   50ms load time  (2x faster!)\n",
    "```\n",
    "\n",
    "## Think of CloudFront Like:\n",
    "\n",
    "### **üìö Library System:**\n",
    "- **Without CloudFront:** One library in Virginia, everyone travels there\n",
    "- **With CloudFront:** Local libraries everywhere with copies of popular books\n",
    "\n",
    "### **üçï Pizza Delivery:**\n",
    "- **Without CloudFront:** One pizza shop, delivers worldwide (slow)\n",
    "- **With CloudFront:** Pizza shops in every city (fast local delivery)\n",
    "\n",
    "### **üì∫ Netflix:**\n",
    "- Netflix doesn't stream movies from one server\n",
    "- They cache popular shows in servers near you\n",
    "- That's essentially what CloudFront does for your website\n",
    "\n",
    "## Bottom Line:\n",
    "\n",
    "**CloudFront turns your slow, HTTP-only S3 website into a fast, secure, professional website with HTTPS that loads quickly anywhere in the world!**\n",
    "\n",
    "It's like having your website magically appear on servers worldwide, making it fast for everyone, not just users near your S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6089b27-7540-4303-8176-35ef0e403bb8",
   "metadata": {},
   "source": [
    "# CloudFront DNS\n",
    "\n",
    "Great question! When you create a CloudFront distribution, AWS gives you a **CloudFront domain name** that you need to point your DNS to. Here's how to get it:\n",
    "\n",
    "## Method 1: Get CloudFront Domain from Python\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def get_cloudfront_domains(bucket_name=None):\n",
    "    \"\"\"Get CloudFront distribution domains\"\"\"\n",
    "    \n",
    "    cloudfront = boto3.client('cloudfront')\n",
    "    \n",
    "    try:\n",
    "        # List all CloudFront distributions\n",
    "        response = cloudfront.list_distributions()\n",
    "        \n",
    "        if 'DistributionList' not in response or response['DistributionList']['Quantity'] == 0:\n",
    "            print(\"‚ùå No CloudFront distributions found\")\n",
    "            return None\n",
    "        \n",
    "        print(\"‚òÅÔ∏è  CloudFront Distributions:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, dist in enumerate(response['DistributionList']['Items'], 1):\n",
    "            dist_id = dist['Id']\n",
    "            domain_name = dist['DomainName']\n",
    "            status = dist['Status']\n",
    "            comment = dist.get('Comment', 'No description')\n",
    "            \n",
    "            # Check if this distribution is for our bucket\n",
    "            origins = dist.get('Origins', {}).get('Items', [])\n",
    "            is_our_bucket = any(bucket_name and bucket_name in origin.get('DomainName', '') \n",
    "                              for origin in origins) if bucket_name else False\n",
    "            \n",
    "            marker = \"üéØ\" if is_our_bucket else \"üìã\"\n",
    "            \n",
    "            print(f\"{marker} Distribution {i}:\")\n",
    "            print(f\"   ID: {dist_id}\")\n",
    "            print(f\"   Domain: {domain_name}\")\n",
    "            print(f\"   Status: {status}\")\n",
    "            print(f\"   Comment: {comment}\")\n",
    "            \n",
    "            # Show custom domains (aliases)\n",
    "            if 'Aliases' in dist and dist['Aliases']['Quantity'] > 0:\n",
    "                aliases = dist['Aliases']['Items']\n",
    "                print(f\"   Custom Domains: {', '.join(aliases)}\")\n",
    "            \n",
    "            # Show what it points to\n",
    "            if origins:\n",
    "                origin_domain = origins[0].get('DomainName', 'Unknown')\n",
    "                print(f\"   Points to: {origin_domain}\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            if is_our_bucket:\n",
    "                return {\n",
    "                    'distribution_id': dist_id,\n",
    "                    'cloudfront_domain': domain_name,\n",
    "                    'status': status,\n",
    "                    'custom_domains': dist.get('Aliases', {}).get('Items', [])\n",
    "                }\n",
    "        \n",
    "        return response['DistributionList']['Items']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting CloudFront distributions: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage - find all distributions\n",
    "all_distributions = get_cloudfront_domains()\n",
    "\n",
    "# Usage - find distribution for specific bucket\n",
    "bucket_distribution = get_cloudfront_domains(\"cpbucket-investigate-001\")\n",
    "```\n",
    "\n",
    "## Method 2: Get Specific Distribution Details\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "def get_distribution_details(distribution_id):\n",
    "    \"\"\"Get detailed info about a specific CloudFront distribution\"\"\"\n",
    "    \n",
    "    cloudfront = boto3.client('cloudfront')\n",
    "    \n",
    "    try:\n",
    "        response = cloudfront.get_distribution(Id=distribution_id)\n",
    "        dist = response['Distribution']\n",
    "        config = dist['DistributionConfig']\n",
    "        \n",
    "        print(f\"‚òÅÔ∏è  CloudFront Distribution Details\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìã ID: {dist['Id']}\")\n",
    "        print(f\"üåê CloudFront Domain: {dist['DomainName']}\")\n",
    "        print(f\"üìä Status: {dist['Status']}\")\n",
    "        print(f\"üïí Last Modified: {dist['LastModifiedTime']}\")\n",
    "        \n",
    "        # Custom domains\n",
    "        if 'Aliases' in config and config['Aliases']['Quantity'] > 0:\n",
    "            print(f\"üè∑Ô∏è  Custom Domains:\")\n",
    "            for alias in config['Aliases']['Items']:\n",
    "                print(f\"   ‚Ä¢ {alias}\")\n",
    "        else:\n",
    "            print(\"üè∑Ô∏è  Custom Domains: None\")\n",
    "        \n",
    "        # Origin (what it points to)\n",
    "        print(f\"üéØ Origin:\")\n",
    "        for origin in config['Origins']['Items']:\n",
    "            print(f\"   ‚Ä¢ {origin['DomainName']}\")\n",
    "        \n",
    "        # SSL Certificate\n",
    "        if 'ViewerCertificate' in config:\n",
    "            cert = config['ViewerCertificate']\n",
    "            if 'ACMCertificateArn' in cert:\n",
    "                print(f\"üîí SSL Certificate: AWS Certificate Manager\")\n",
    "            elif cert.get('CloudFrontDefaultCertificate'):\n",
    "                print(f\"üîí SSL Certificate: CloudFront Default (*.cloudfront.net only)\")\n",
    "            else:\n",
    "                print(f\"üîí SSL Certificate: Custom\")\n",
    "        \n",
    "        return {\n",
    "            'cloudfront_domain': dist['DomainName'],\n",
    "            'custom_domains': config.get('Aliases', {}).get('Items', []),\n",
    "            'status': dist['Status']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting distribution details: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "# details = get_distribution_details(\"E1234567890ABC\")\n",
    "```\n",
    "\n",
    "## Method 3: AWS CLI (Alternative)\n",
    "\n",
    "```bash\n",
    "# List all CloudFront distributions\n",
    "aws cloudfront list-distributions --query 'DistributionList.Items[*].[Id,DomainName,Comment]' --output table\n",
    "\n",
    "# Get specific distribution details\n",
    "aws cloudfront get-distribution --id E1234567890ABC --query 'Distribution.[Id,DomainName,Status]'\n",
    "```\n",
    "\n",
    "## Method 4: Create Distribution and Get Domain\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "def create_and_get_cloudfront_domain(bucket_name, custom_domain=None):\n",
    "    \"\"\"Create CloudFront distribution and return the domain to use in DNS\"\"\"\n",
    "    \n",
    "    cloudfront = boto3.client('cloudfront')\n",
    "    \n",
    "    distribution_config = {\n",
    "        'CallerReference': f'{bucket_name}-{int(time.time())}',\n",
    "        'Comment': f'CloudFront for {bucket_name}',\n",
    "        'Enabled': True,\n",
    "        'Origins': {\n",
    "            'Quantity': 1,\n",
    "            'Items': [{\n",
    "                'Id': 's3-origin',\n",
    "                'DomainName': f'{bucket_name}.s3-website-us-east-1.amazonaws.com',\n",
    "                'CustomOriginConfig': {\n",
    "                    'HTTPPort': 80,\n",
    "                    'HTTPSPort': 443,\n",
    "                    'OriginProtocolPolicy': 'http-only'\n",
    "                }\n",
    "            }]\n",
    "        },\n",
    "        'DefaultCacheBehavior': {\n",
    "            'TargetOriginId': 's3-origin',\n",
    "            'ViewerProtocolPolicy': 'redirect-to-https',\n",
    "            'TrustedSigners': {'Enabled': False, 'Quantity': 0},\n",
    "            'ForwardedValues': {\n",
    "                'QueryString': False,\n",
    "                'Cookies': {'Forward': 'none'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add custom domain if provided\n",
    "    if custom_domain:\n",
    "        distribution_config['Aliases'] = {\n",
    "            'Quantity': 1,\n",
    "            'Items': [custom_domain]\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = cloudfront.create_distribution(DistributionConfig=distribution_config)\n",
    "        \n",
    "        distribution_id = response['Distribution']['Id']\n",
    "        cloudfront_domain = response['Distribution']['DomainName']\n",
    "        \n",
    "        print(f\"‚úÖ CloudFront distribution created!\")\n",
    "        print(f\"üìã Distribution ID: {distribution_id}\")\n",
    "        print(f\"üåê CloudFront Domain: {cloudfront_domain}\")\n",
    "        print(f\"‚è≥ Status: Deploying (5-15 minutes)\")\n",
    "        \n",
    "        print(f\"\\nüéØ DNS Setup Instructions:\")\n",
    "        if custom_domain:\n",
    "            print(f\"Create this DNS record:\")\n",
    "            print(f\"   Type: CNAME\")\n",
    "            print(f\"   Name: {custom_domain}\")\n",
    "            print(f\"   Value: {cloudfront_domain}\")\n",
    "            print(f\"   TTL: 300\")\n",
    "            print(f\"\\nüåê Result: https://{custom_domain}\")\n",
    "        else:\n",
    "            print(f\"Direct access: https://{cloudfront_domain}\")\n",
    "        \n",
    "        return {\n",
    "            'distribution_id': distribution_id,\n",
    "            'cloudfront_domain': cloudfront_domain,\n",
    "            'dns_target': cloudfront_domain\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating CloudFront: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "result = create_and_get_cloudfront_domain(\n",
    "    bucket_name=\"cpbucket-investigate-001\",\n",
    "    custom_domain=\"mysite.example.com\"\n",
    ")\n",
    "```\n",
    "\n",
    "## What You Get from CloudFront:\n",
    "\n",
    "### **CloudFront Domain Example:**\n",
    "```\n",
    "d1234567890abc.cloudfront.net\n",
    "```\n",
    "\n",
    "### **This is what you use in DNS:**\n",
    "\n",
    "**For CNAME record:**\n",
    "```\n",
    "Type: CNAME\n",
    "Name: mysite\n",
    "Value: d1234567890abc.cloudfront.net\n",
    "TTL: 300\n",
    "```\n",
    "\n",
    "**For Route 53 Alias record:**\n",
    "```\n",
    "Type: A - Alias\n",
    "Name: mysite.example.com\n",
    "Alias Target: d1234567890abc.cloudfront.net\n",
    "```\n",
    "\n",
    "## Complete DNS Setup Example:\n",
    "\n",
    "```python\n",
    "def show_dns_instructions(cloudfront_domain, custom_domain):\n",
    "    \"\"\"Show exact DNS setup instructions\"\"\"\n",
    "    \n",
    "    print(f\"üåê DNS Setup for {custom_domain}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"üìã CloudFront Domain: {cloudfront_domain}\")\n",
    "    print(f\"üéØ Your Custom Domain: {custom_domain}\")\n",
    "    \n",
    "    print(f\"\\nüìù DNS Record to Create:\")\n",
    "    print(f\"   Type: CNAME\")\n",
    "    print(f\"   Name: {custom_domain.split('.')[0]}\")  # e.g., \"mysite\" from \"mysite.example.com\"\n",
    "    print(f\"   Value: {cloudfront_domain}\")\n",
    "    print(f\"   TTL: 300 (5 minutes)\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Propagation Time: 5-60 minutes\")\n",
    "    print(f\"‚úÖ Final URL: https://{custom_domain}\")\n",
    "    \n",
    "    print(f\"\\nüß™ Test Commands:\")\n",
    "    print(f\"   dig {custom_domain}\")\n",
    "    print(f\"   nslookup {custom_domain}\")\n",
    "\n",
    "# Usage\n",
    "show_dns_instructions(\"d1234567890abc.cloudfront.net\", \"mysite.example.com\")\n",
    "```\n",
    "\n",
    "## Quick Check If You Already Have CloudFront:\n",
    "\n",
    "```python\n",
    "# Quick check for existing distributions\n",
    "distributions = get_cloudfront_domains(\"cpbucket-investigate-001\")\n",
    "if distributions:\n",
    "    print(f\"‚úÖ Found existing CloudFront distribution\")\n",
    "    print(f\"üåê Use this in DNS: {distributions['cloudfront_domain']}\")\n",
    "else:\n",
    "    print(\"‚ùå No CloudFront distribution found - need to create one\")\n",
    "```\n",
    "\n",
    "**The key takeaway:** The CloudFront domain (like `d1234567890abc.cloudfront.net`) is what you point your DNS records to, not your S3 bucket URL!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
