{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c10928-d365-47b1-ba69-9ea31317c75b",
   "metadata": {},
   "source": [
    "## Get Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89a26cb-1dd6-45d9-b78c-97cf815aa4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python-dotenv:\n",
      "API Key: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Method 1: Using python-dotenv (recommended)\n",
    "# First install: pip install python-dotenv\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    # Load .env file from home directory\n",
    "    dotenv_path = Path.home() / '.env'\n",
    "    load_dotenv(dotenv_path)\n",
    "    \n",
    "    # Now you can access environment variables\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "#    database_url = os.getenv('DATABASE_URL')\n",
    "    \n",
    "    print(\"Using python-dotenv:\")\n",
    "    print(f\"API Key: {api_key}\")\n",
    "#    print(f\"Database URL: {database_url}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed. Install with: pip install python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1d846c-73da-4b45-9d98-12060a507ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Tell me a joke about cats\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Tell me a joke about cats\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.19s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"setup\\\":\\\"Why was the cat sitting on the computer?\\\",\\\"punchline\\\":\\\"Because it wanted to keep an eye on the mouse!\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"setup\\\":\\\"Why was the cat sitting on the computer?\\\",\\\"punchline\\\":\\\"Because it wanted to keep an eye on the mouse!\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"parsed\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"__main__\",\n",
      "                  \"Joke\"\n",
      "                ],\n",
      "                \"repr\": \"Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!')\"\n",
      "              },\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 29,\n",
      "                \"prompt_tokens\": 82,\n",
      "                \"total_tokens\": 111,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "              \"id\": \"chatcmpl-Br0OE9l07UmjYtSX5TmZ6z7oqSZeO\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--4ba8d016-509f-40ce-979c-9523738be1e2-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 82,\n",
      "              \"output_tokens\": 29,\n",
      "              \"total_tokens\": 111,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 29,\n",
      "      \"prompt_tokens\": 82,\n",
      "      \"total_tokens\": 111,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "    \"id\": \"chatcmpl-Br0OE9l07UmjYtSX5TmZ6z7oqSZeO\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.19s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "setup='Why was the cat sitting on the computer?' punchline='Because it wanted to keep an eye on the mouse!'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enable global debugging\n",
    "\n",
    "import langchain\n",
    "langchain.debug = True  # Enable global debugging\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(Joke)\n",
    "\n",
    "result = model.invoke(\"Tell me a joke about cats\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d5ba7-6094-4856-a02e-5d00f1bbcde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
